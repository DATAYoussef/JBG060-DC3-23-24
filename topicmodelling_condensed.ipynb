{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, OPTICS, SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the data and perform preprocessing\n",
    "\n",
    "df = pd.read_csv(\"data/articles_summary_cleaned.csv\", parse_dates=[\"date\"]) # Read data into 'df' dataframe\n",
    "print(df.shape) # Print dataframe shape\n",
    "\n",
    "docs = df[\"summary\"].tolist() # Create a list containing all article summaries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dccca530c95eb2c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists('southsudan_model'):\n",
    "    bertopic = BERTopic.load('southsudan_model')\n",
    "else:\n",
    "    bertopic = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True) # Initialize the BERTopic model\n",
    "\n",
    "    bertopic.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    bertopic.save(\"southsudan_model\") # Save the trained model as \"southsudan_model\"\n",
    " \n",
    "if os.path.exists('kmeans_model'):\n",
    "    kmeans_model = BERTopic.load('kmeans_model')\n",
    "else:\n",
    "    cluster_model = KMeans(n_clusters=10)\n",
    "    kmeans_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model) # Initialize the BERTopic model\n",
    "\n",
    "    kmeans_model.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    kmeans_model.save(\"kmeans_model\") # Save the trained model \n",
    "\n",
    "if os.path.exists('agglomerative_model'):\n",
    "    agglomerative_model = BERTopic.load('agglomerative_model')\n",
    "else:\n",
    "    cluster_model = AgglomerativeClustering(n_clusters=10)\n",
    "    agglomerative_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model) # Initialize the BERTopic model\n",
    "\n",
    "    agglomerative_model.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    agglomerative_model.save(\"agglomerative_model\") # Save the trained model \n",
    "\n",
    "if os.path.exists('optics_model'):\n",
    "    optics_model = BERTopic.load('optics_model')\n",
    "else:\n",
    "    cluster_model = OPTICS(min_samples=5)  # Customize the OPTICS parameters as needed\n",
    "    optics_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model)\n",
    "\n",
    "    optics_model.fit_transform(docs)\n",
    "    optics_model.save(\"optics_model\")\n",
    "\n",
    "if os.path.exists('spectral_model'):\n",
    "    spectral_model = BERTopic.load('spectral_model')\n",
    "else:\n",
    "    cluster_model = SpectralClustering(n_clusters=10)  # Customize the Spectral Clustering parameters as needed\n",
    "    spectral_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model)\n",
    "\n",
    "    spectral_model.fit_transform(docs)\n",
    "    spectral_model.save(\"spectral_model\")\n",
    "    \n",
    "models = [bertopic, kmeans_model, agglomerative_model, optics_model, spectral_model]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b391d9f9c98c5a56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We create a function to calculate a list of the top n topics related to (a) given keyword(s)\n",
    "\n",
    "def get_relevant_topics(bertopic_model, keywords, top_n):\n",
    "    \n",
    "    if type(keywords) is str: keywords = [keywords] # If a single string is provided convert it to list type\n",
    "    \n",
    "    relevant_topics = list() # Initilize an empty list of relevant topics\n",
    "    \n",
    "    for keyword in keywords: # Iterate through list of keywords\n",
    "        \n",
    "        # Find the top n number of topics related to the current keyword(s)\n",
    "        topics = bertopic_model.find_topics(keyword, top_n = top_n)\n",
    "        \n",
    "        # Add the topics to the list of relevant topics in the form of (topic_id, relevancy)\n",
    "        relevant_topics.extend(\n",
    "            zip(topics[0], topics[1]) # topics[0] = topic_id, topics[1] = relevancy\n",
    "        )\n",
    "    \n",
    "    \n",
    "    relevant_topics.sort(key=lambda x: x[1]) # Sort the list of topics on ASCENDING ORDER of relevancy\n",
    "    \n",
    "    # Get a list of the set of unique topics (with greates relevancy in case of duplicate topics)\n",
    "    relevant_topics = list(dict(relevant_topics).items())\n",
    "    \n",
    "    \n",
    "    relevant_topics.sort(key=lambda x: x[1], reverse=True) # Now sort the list of topics on DESCENDING ORDER of relevancy\n",
    "    \n",
    "    return relevant_topics[:10] # Return a list of the top_n unique relevant topics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfe027991a5a57d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keyword_sets = keyword_sets = [\n",
    "    (['hunger', 'food insecurity', 'conflict'], 'hunger'),\n",
    "    (['refugees', 'displaced'], 'refugees'),\n",
    "    (['humanitarian'], 'humanitarian'),\n",
    "    (['conflict', 'fighting', 'murder', 'military'], 'conflict'),\n",
    "    ([\"politics\", \"government\", \"elections\", \"independence\"], 'politics'),\n",
    "    (['aid', 'assistance', 'relief'], 'aid')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4003dcb235be3a72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for keywords, label in keyword_sets:\n",
    "        # Get the top 10 topics related to the current set of keywords\n",
    "        relevant_topics = get_relevant_topics(bertopic_model=agglomerative_model, keywords=keywords, top_n=15)\n",
    "        \n",
    "        # Create a list of topic IDs\n",
    "        topic_ids = [el[0] for el in relevant_topics]\n",
    "        \n",
    "        # Print the relevant topics\n",
    "        print(f\"Top 10 topics related to '{label}':\")\n",
    "        for topic_id, relevancy in relevant_topics:\n",
    "            print(topic_id, relevancy)\n",
    "        \n",
    "        # Add a boolean column to the 'df' DataFrame if the topic is in the list of relevant topics\n",
    "        df[label] = [t in topic_ids for t in bertopic.topics_]\n",
    "        print(f\"Model: {model}\")\n",
    "        print(len(df))\n",
    "        print(len(df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False)]))\n",
    "        print(len(df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False) & (df[\"politics\"] == False) & (df[\"aid\"] == False)]))\n",
    "        print(20* \"-\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17047ba2d9503307"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unsorted = df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False) & (df[\"politics\"] == False)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c67eb293fcb8885e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Refit models on unsorted data\n",
    "if os.path.exists('refit_kmeans'):\n",
    "    refit_kmeans = BERTopic.load('refit_kmeans')\n",
    "else:\n",
    "    refit_kmeans = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=KMeans(n_clusters=10))\n",
    "    refit_kmeans.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_kmeans.save(\"refit_kmeans\")\n",
    "\n",
    "if os.path.exists('refit_agglomerative'):\n",
    "    refit_agglomerative = BERTopic.load('refit_optics')\n",
    "else:\n",
    "    refit_agglomerative = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=AgglomerativeClustering(n_clusters=10))\n",
    "    refit_agglomerative.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_agglomerative.save(\"refit_agglomerative\")\n",
    "\n",
    "if os.path.exists('refit_spectral'):\n",
    "    refit_spectral = BERTopic.load('refit_spectral')\n",
    "else:\n",
    "    refit_spectral = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=SpectralClustering(n_clusters=10))\n",
    "    refit_spectral.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_spectral.save(\"refit_spectral\")\n",
    "\n",
    "refitted_models = [refit_kmeans, refit_agglomerative, refit_spectral]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dbf394d24b5c5e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for model in refitted_models:\n",
    "    for keywords, label in keyword_sets:\n",
    "        # Get the top 10 topics related to the current set of keywords\n",
    "        relevant_topics = get_relevant_topics(bertopic_model=model, keywords=keywords, top_n=15)\n",
    "        \n",
    "        # Create a list of topic IDs\n",
    "        topic_ids = [el[0] for el in relevant_topics]\n",
    "        \n",
    "        # Print the relevant topics\n",
    "        print(f\"Top 10 topics related to '{label}':\")\n",
    "        for topic_id, relevancy in relevant_topics:\n",
    "            print(topic_id, relevancy)\n",
    "        \n",
    "        # Add a boolean column to 'unsorted' DataFrame if the topic is in the list of relevant topics\n",
    "        unsorted[label] = [t in topic_ids for t in bertopic.topics_]\n",
    "        print(f\"Model: {model}\")\n",
    "        print(len(unsorted))\n",
    "        print(len(unsorted[(unsorted[\"hunger\"]==False) & (unsorted[\"refugees\"] == False) & (unsorted[\"humanitarian\"] == False) & (unsorted[\"conflict\"] == False)]))\n",
    "        print(len(unsorted[(unsorted[\"hunger\"]==False) & (unsorted[\"refugees\"] == False) & (unsorted[\"humanitarian\"] == False) & (unsorted[\"conflict\"] == False) & (unsorted[\"politics\"] == False) & (unsorted[\"aid\"] == False)]))\n",
    "        print(20* \"-\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8c1fc0302a3b8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
