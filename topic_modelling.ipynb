{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling using BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries/data required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:12:56.599741600Z",
     "start_time": "2023-09-25T11:12:42.035043800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20210777\\Anaconda3\\envs\\DC3\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\20210777\\Anaconda3\\envs\\DC3\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\20210777\\Anaconda3\\envs\\DC3\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\20210777\\Anaconda3\\envs\\DC3\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, OPTICS, SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:12:56.854322200Z",
     "start_time": "2023-09-25T11:12:56.599741600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18520, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read the data and perform preprocessing\n",
    "\n",
    "df = pd.read_csv(\"data/articles_summary_cleaned.csv\", parse_dates=[\"date\"]) # Read data into 'df' dataframe\n",
    "print(df.shape) # Print dataframe shape\n",
    "\n",
    "docs = df[\"summary\"].tolist() # Create a list containing all article summaries\n",
    "\n",
    "# df.head() # Show first 5 dataframe entries\n",
    "# docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting BERTopic\n",
    "\n",
    "This might take a while on a CPU. In the background a pre-trained Large Language Model, called the sentence embedder, is used to convert the articles to a semantic vector space. We then perform clustering in this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:16.826413400Z",
     "start_time": "2023-09-25T11:12:56.857546Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists('southsudan_model'):\n",
    "    bertopic = BERTopic.load('southsudan_model')\n",
    "else:\n",
    "    bertopic = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True) # Initialize the BERTopic model\n",
    "\n",
    "    bertopic.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    bertopic.save(\"southsudan_model\") # Save the trained model as \"southsudan_model\"\n",
    " \n",
    "if os.path.exists('kmeans_model'):\n",
    "    kmeans_model = BERTopic.load('kmeans_model')\n",
    "else:\n",
    "    cluster_model = KMeans(n_clusters=10)\n",
    "    kmeans_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model) # Initialize the BERTopic model\n",
    "\n",
    "    kmeans_model.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    kmeans_model.save(\"kmeans_model\") # Save the trained model \n",
    "\n",
    "if os.path.exists('agglomerative_model'):\n",
    "    agglomerative_model = BERTopic.load('agglomerative_model')\n",
    "else:\n",
    "    cluster_model = AgglomerativeClustering(n_clusters=10)\n",
    "    agglomerative_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model) # Initialize the BERTopic model\n",
    "\n",
    "    agglomerative_model.fit_transform(docs) # Fit the model to the list of article summaries\n",
    "    agglomerative_model.save(\"agglomerative_model\") # Save the trained model \n",
    "\n",
    "if os.path.exists('optics_model'):\n",
    "    optics_model = BERTopic.load('optics_model')\n",
    "else:\n",
    "    cluster_model = OPTICS(min_samples=5)  # Customize the OPTICS parameters as needed\n",
    "    optics_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model)\n",
    "\n",
    "    optics_model.fit_transform(docs)\n",
    "    optics_model.save(\"optics_model\")\n",
    "\n",
    "if os.path.exists('spectral_model'):\n",
    "    spectral_model = BERTopic.load('spectral_model')\n",
    "else:\n",
    "    cluster_model = SpectralClustering(n_clusters=10)  # Customize the Spectral Clustering parameters as needed\n",
    "    spectral_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=cluster_model)\n",
    "\n",
    "    spectral_model.fit_transform(docs)\n",
    "    spectral_model.save(\"spectral_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:16.841866900Z",
     "start_time": "2023-09-25T11:13:16.826413400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Due to the modularity of the model, there is a lot of randomness that hinders reproducibility of the model.\n",
    "#To fight this, you can for example set random state in the dimensionality reduction step via the following lines \n",
    "#or explore a different approach\n",
    "\n",
    "#from bertopic import BERTopic\n",
    "#from umap import UMAP\n",
    "\n",
    "#umap_model = UMAP(n_neighbors=15, n_components=5, \n",
    "#                  min_dist=0.0, metric='cosine', random_state=42)\n",
    "#topic_model = BERTopic(umap_model=umap_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive visualization of the vector space\n",
    "\n",
    "As you can see, documents with related topics are close in the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:16.904325500Z",
     "start_time": "2023-09-25T11:13:16.857461100Z"
    }
   },
   "outputs": [],
   "source": [
    "# bertopic.visualize_documents(docs) # Create a plot of the topics, this may take a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating smaller topics\n",
    "\n",
    "Within our list of topics, we find topics that are semantically closest to 4 keywords:\n",
    "\n",
    "\"Hunger\", \"Refugees\", \"Conflict\", and \"Humanitarian\".\n",
    "\n",
    "**Feel free to change this approach!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:16.904325500Z",
     "start_time": "2023-09-25T11:13:16.857461100Z"
    }
   },
   "outputs": [],
   "source": [
    "# We create a function to calculate a list of the top n topics related to (a) given keyword(s)\n",
    "\n",
    "def get_relevant_topics(bertopic_model, keywords, top_n):\n",
    "    '''\n",
    "    Retrieve a list of the top n number of relevant topics to the provided (list of) keyword(s)\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        bertopic_model: a (fitted) BERTopic model object\n",
    "        \n",
    "        keywords:   a string containing one or multiple keywords to match against,\n",
    "                    \n",
    "                    This can also be a list in the form of ['keyword(s)', keyword(s), ...]\n",
    "                    \n",
    "                    In this case a maximum of top_n topics will be found per list element \n",
    "                    and subsetted to the top_n most relevant topics.\n",
    "                    \n",
    "                    !!!\n",
    "                    Take care that this method only considers the relevancy per inputted keyword(s) \n",
    "                    and not the relevancy to the combined list of keywords.\n",
    "                    \n",
    "                    In other words, topics that appear in the output might be significantly related to a \n",
    "                    particular element in the list of keywords but not so to any other element, \n",
    "                    \n",
    "                    while topics that do not appear in the output might be significantly related to the \n",
    "                    combined list of keywords but not much to any of the keyword(s) in particular.\n",
    "                    !!!\n",
    "                    \n",
    "        top_n: an integer indicating the number of desired relevant topics to be retrieved\n",
    "        \n",
    "        \n",
    "        Return: a list of the top_n (or less) topics most relevant to the (list of) provided keyword(s)\n",
    "    '''\n",
    "    \n",
    "    if type(keywords) is str: keywords = [keywords] # If a single string is provided convert it to list type\n",
    "    \n",
    "    relevant_topics = list() # Initilize an empty list of relevant topics\n",
    "    \n",
    "    for keyword in keywords: # Iterate through list of keywords\n",
    "        \n",
    "        # Find the top n number of topics related to the current keyword(s)\n",
    "        topics = bertopic_model.find_topics(keyword, top_n = top_n)\n",
    "        \n",
    "        # Add the topics to the list of relevant topics in the form of (topic_id, relevancy)\n",
    "        relevant_topics.extend(\n",
    "            zip(topics[0], topics[1]) # topics[0] = topic_id, topics[1] = relevancy\n",
    "        )\n",
    "    \n",
    "    \n",
    "    relevant_topics.sort(key=lambda x: x[1]) # Sort the list of topics on ASCENDING ORDER of relevancy\n",
    "    \n",
    "    # Get a list of the set of unique topics (with greates relevancy in case of duplicate topics)\n",
    "    relevant_topics = list(dict(relevant_topics).items())\n",
    "    \n",
    "    \n",
    "    relevant_topics.sort(key=lambda x: x[1], reverse=True) # Now sort the list of topics on DESCENDING ORDER of relevancy\n",
    "    \n",
    "    return relevant_topics[:10] # Return a list of the top_n unique relevant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.154257700Z",
     "start_time": "2023-09-25T11:13:16.904325500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.38241392\n",
      "3 0.37269127\n",
      "1 0.35268196\n",
      "5 0.33064908\n",
      "0 0.32147127\n",
      "2 0.29207075\n",
      "6 0.26719108\n",
      "8 0.25609177\n",
      "4 0.22635308\n",
      "9 0.20630968\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keywords 'hunger' and 'food insecurity'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=['hunger', 'food insecurity', 'conflict'], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"hunger\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]\n",
    "# df[\"hunger\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.232396300Z",
     "start_time": "2023-09-25T11:13:17.138640300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.5495614\n",
      "6 0.43483782\n",
      "5 0.4260249\n",
      "7 0.41448748\n",
      "0 0.396513\n",
      "1 0.38125336\n",
      "3 0.3779419\n",
      "8 0.33971408\n",
      "4 0.33799133\n",
      "9 0.24752645\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keywords 'refugees' and 'displaced'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=['refugees', 'displaced'], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"refugees\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.232396300Z",
     "start_time": "2023-09-25T11:13:17.185503400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.6128026\n",
      "5 0.55738395\n",
      "3 0.506997\n",
      "6 0.4951638\n",
      "7 0.4824435\n",
      "0 0.4809367\n",
      "1 0.47879434\n",
      "4 0.43003786\n",
      "8 0.42116326\n",
      "9 0.3122993\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keyword 'humanitarian'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=['humanitarian'], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"humanitarian\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.357337Z",
     "start_time": "2023-09-25T11:13:17.216771700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.38241392\n",
      "3 0.37269127\n",
      "1 0.35268196\n",
      "5 0.33064908\n",
      "0 0.32147127\n",
      "6 0.26719108\n",
      "8 0.25948998\n",
      "2 0.22942087\n",
      "4 0.22635308\n",
      "9 0.20630968\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keywords 'conflict', 'fighting', and 'murder'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=['conflict', 'fighting', 'murder', 'military'], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"conflict\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.33187532\n",
      "4 0.3152099\n",
      "3 0.30114138\n",
      "8 0.28646624\n",
      "1 0.2858027\n",
      "7 0.2836869\n",
      "6 0.26377165\n",
      "2 0.26223248\n",
      "5 0.25914246\n",
      "9 0.17086889\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keywords 'politics', 'government', and 'elections'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=[\"politics\", \"government\", \"elections\", \"independence\"], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"politics\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.451065500Z",
     "start_time": "2023-09-25T11:13:17.294857900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.44024152\n",
      "6 0.33476654\n",
      "4 0.3068655\n",
      "5 0.2967866\n",
      "1 0.2879024\n",
      "7 0.2836157\n",
      "3 0.28057277\n",
      "0 0.2609885\n",
      "9 0.21116325\n",
      "8 0.20132065\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 topics related to the keywords 'aid', 'assistance', and 'relief'\n",
    "relevant_topics = get_relevant_topics(bertopic_model = agglomerative_model, keywords=['aid', 'assistance', 'relief'], top_n=15)\n",
    "\n",
    "topic_ids = [el[0] for el in relevant_topics] # Create seperate list of topic IDs\n",
    "\n",
    "for topic_id, relevancy in relevant_topics: # Print neat list of (topic_id, relevancy) tuples\n",
    "    print(topic_id, relevancy)\n",
    "    \n",
    "df[\"aid\"] = [t in topic_ids for t in bertopic.topics_] # Add boolean column to df if topic in list of relevant topics\n",
    "\n",
    "# View the Count, Name, Representation, and Representative Docs for the relevant topics\n",
    "# bertopic.get_topic_info().set_index('Topic').loc[topic_ids]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.466690700Z",
     "start_time": "2023-09-25T11:13:17.372985600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"data/articles_summary_cleaned.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Combine article summaries with the newly created features\n",
    "df = original_df.merge(\n",
    "    df[[\"summary\", \"hunger\", \"refugees\", \"humanitarian\", \"conflict\", \"politics\", \"aid\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"summary\",\n",
    "    right_on=\"summary\",\n",
    ")\n",
    "\n",
    "# df.to_csv(\"data/articles_topics.csv\", index=False) # Save DataFrame to articles_topics.csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.775564900Z",
     "start_time": "2023-09-25T11:13:17.435441600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18520\n",
      "16224\n",
      "16224\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False)]))\n",
    "print(len(df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False) & (df[\"politics\"] == False) & (df[\"aid\"] == False)]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:17.837914400Z",
     "start_time": "2023-09-25T11:13:17.791061300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             summary       date  \\\n0  The article discusses the passing of the new C... 2011-07-07   \n1  The article discusses the military actions tak... 2011-07-03   \n3  The article discusses the upcoming independenc... 2011-07-04   \n4  The article discusses the need for South Sudan... 2011-07-02   \n5  The article discusses the United States' respo... 2011-07-06   \n\n  location_article       lat        lng  hunger  refugees  humanitarian  \\\n0             Juba  4.859363  31.571250   False     False         False   \n1            Abyei  9.838551  28.486396   False     False         False   \n3      South Sudan  6.876992  31.306979   False     False         False   \n4             Juba  4.859363  31.571250   False     False         False   \n5      Addis Ababa  8.980603  38.757761   False     False         False   \n\n   conflict  politics    aid  \n0     False     False  False  \n1     False     False  False  \n3     False     False  False  \n4     False     False  False  \n5     False     False  False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>date</th>\n      <th>location_article</th>\n      <th>lat</th>\n      <th>lng</th>\n      <th>hunger</th>\n      <th>refugees</th>\n      <th>humanitarian</th>\n      <th>conflict</th>\n      <th>politics</th>\n      <th>aid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The article discusses the passing of the new C...</td>\n      <td>2011-07-07</td>\n      <td>Juba</td>\n      <td>4.859363</td>\n      <td>31.571250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The article discusses the military actions tak...</td>\n      <td>2011-07-03</td>\n      <td>Abyei</td>\n      <td>9.838551</td>\n      <td>28.486396</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The article discusses the upcoming independenc...</td>\n      <td>2011-07-04</td>\n      <td>South Sudan</td>\n      <td>6.876992</td>\n      <td>31.306979</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The article discusses the need for South Sudan...</td>\n      <td>2011-07-02</td>\n      <td>Juba</td>\n      <td>4.859363</td>\n      <td>31.571250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The article discusses the United States' respo...</td>\n      <td>2011-07-06</td>\n      <td>Addis Ababa</td>\n      <td>8.980603</td>\n      <td>38.757761</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsorted = df[(df[\"hunger\"]==False) & (df[\"refugees\"] == False) & (df[\"humanitarian\"] == False) & (df[\"conflict\"] == False) & (df[\"politics\"] == False)]\n",
    "unsorted.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:18.041041300Z",
     "start_time": "2023-09-25T11:13:17.837914400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# if os.path.exists('southsudan_model_politics'):\n",
    "#     bertopic = BERTopic.load('southsudan_model_politics')\n",
    "# else:\n",
    "#     bertopic = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True) # Initialize the BERTopic model\n",
    "# \n",
    "#     bertopic.fit_transform(unsorted[\"summary\"].tolist()) # Fit the model to the list of article summaries\n",
    "#     bertopic.save(\"southsudan_model_politics\") # Save the trained model as \"southsudan_model\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:18.041041300Z",
     "start_time": "2023-09-25T11:13:17.947299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# uns_list = unsorted[\"summary\"].tolist()\n",
    "# #Write the list of uns_list to text file using utf-8 encoding\n",
    "# with open(\"data/uns_list.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for s in uns_list:\n",
    "#         f.write(str(s) +\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T11:13:18.041041300Z",
     "start_time": "2023-09-25T11:13:17.962893400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/507 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e9863b068694315b8a894651504b911"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:21:24,581 - BERTopic - Transformed documents to Embeddings\n",
      "2023-09-25 13:21:50,029 - BERTopic - Reduced dimensionality\n",
      "  File \"C:\\Users\\20210777\\Anaconda3\\envs\\DC3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n",
      "2023-09-25 13:21:50,482 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/507 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d68ca60d606c49669c1970079de49d90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refit models on unsorted data\n",
    "if os.path.exists('refit_kmeans'):\n",
    "    refit_kmeans = BERTopic.load('refit_kmeans')\n",
    "else:\n",
    "    refit_kmeans = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=KMeans(n_clusters=10))\n",
    "    refit_kmeans.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_kmeans.save(\"refit_kmeans\")\n",
    "\n",
    "if os.path.exists('refit_agglomerative'):\n",
    "    refit_agglomerative = BERTopic.load('refit_optics')\n",
    "else:\n",
    "    refit_agglomerative = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=AgglomerativeClustering(n_clusters=10))\n",
    "    refit_agglomerative.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_agglomerative.save(\"refit_agglomerative\")\n",
    "\n",
    "if os.path.exists('refit_spectral'):\n",
    "    refit_spectral = BERTopic.load('refit_spectral')\n",
    "else:\n",
    "    refit_spectral = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model=SpectralClustering(n_clusters=10))\n",
    "    refit_spectral.fit_transform(unsorted[\"summary\"].tolist())\n",
    "    refit_spectral.save(\"refit_spectral\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-25T11:13:17.994168900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_model = refit_agglomerative"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a list of keyword sets, each with keywords and a label\n",
    "keyword_sets = [\n",
    "    (['hunger', 'food insecurity', 'conflict'], 'hunger'),\n",
    "    (['refugees', 'displaced'], 'refugees'),\n",
    "    (['humanitarian'], 'humanitarian'),\n",
    "    (['conflict', 'fighting', 'murder', 'military'], 'conflict'),\n",
    "    ([\"politics\", \"government\", \"elections\", \"independence\"], 'politics')\n",
    "]\n",
    "\n",
    "for keywords, label in keyword_sets:\n",
    "    # Get the top 10 topics related to the current set of keywords\n",
    "    relevant_topics = get_relevant_topics(bertopic_model=current_model, keywords=keywords, top_n=15)\n",
    "    \n",
    "    # Create a list of topic IDs\n",
    "    topic_ids = [el[0] for el in relevant_topics]\n",
    "    \n",
    "    # Print the relevant topics\n",
    "    print(f\"Top 10 topics related to '{label}':\")\n",
    "    for topic_id, relevancy in relevant_topics:\n",
    "        print(topic_id, relevancy)\n",
    "    \n",
    "    # Add a boolean column to 'unsorted' DataFrame if the topic is in the list of relevant topics\n",
    "    unsorted[label] = [t in topic_ids for t in bertopic.topics_]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
